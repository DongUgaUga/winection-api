import numpy as np
from collections import deque, Counter
from tensorflow.keras.models import load_model
from core.log.logging import logger

# ëª¨ë¸ ë° ë¼ë²¨ ë¡œë“œ
model = load_model("src/resources/sign_model.h5")
class_names = np.load("src/resources/class_names.npy", allow_pickle=True)

# ì„¤ì •ê°’
WINDOW_SIZE = 30
CONFIDENCE_THRESHOLD = 0.7
PREDICTION_HISTORY_SIZE = 10
MIN_CONFIRM_COUNT = 7

HAND_ABSENCE_THRESHOLD = 1e-4
HAND_ABSENCE_FRAME_COUNT = 30  # 1ì´ˆê°„ ì†ì´ ì•ˆ ë³´ì´ë©´ ì¢…ë£Œ

# ìƒíƒœ ì €ì¥ìš© ì „ì—­ ë³€ìˆ˜
prediction_history = deque(maxlen=PREDICTION_HISTORY_SIZE)
last_landmark = None
hand_absent_counter = 0

def ksl_to_korean(sequence: dict) -> str:
    global last_landmark, hand_absent_counter

    pose = sequence.get('pose', [])
    if len(pose) < WINDOW_SIZE:
        logger.warning(f"[ì…ë ¥ ë¶€ì¡±] í”„ë ˆì„ ìˆ˜ ë¶€ì¡±: {len(pose)}í”„ë ˆì„")
        return ""

    logger.info(f"[ì…ë ¥ ìˆ˜ì‹ ] ì´ í”„ë ˆì„ ìˆ˜: {len(pose)}")

    frames = []
    for idx, frame in enumerate(pose):
        if len(frame) != 75:
            logger.warning(f"[í”„ë ˆì„ ì˜¤ë¥˜] {idx}ë²ˆì§¸ í”„ë ˆì„ì´ 75ê°œ landmark ì•„ë‹˜: {len(frame)}ê°œ")
            return ""
        coords = np.array([[lm['x'], lm['y'], lm['z']] for lm in frame], dtype=np.float32).flatten()
        frames.append(coords)

    frames = np.array(frames, dtype=np.float32)
    word_output = ""

    for i in range(len(frames) - WINDOW_SIZE + 1):
        window = frames[i:i+WINDOW_SIZE]
        pred = model.predict(np.expand_dims(window, axis=0), verbose=0)[0]
        max_idx = int(np.argmax(pred))
        confidence = float(pred[max_idx])
        label = str(class_names[max_idx])

        logger.info(f"[ì˜ˆì¸¡] ìœˆë„ìš° {i} â†’ '{label}' (ì‹ ë¢°ë„: {confidence:.3f})")

        if confidence >= CONFIDENCE_THRESHOLD:
            prediction_history.append(label)
            logger.debug(f"[ëˆ„ì ] '{label}' ì˜ˆì¸¡ ì¶”ê°€ â†’ íˆìŠ¤í† ë¦¬: {list(prediction_history)}")
        else:
            logger.debug(f"[ë¬´ì‹œ] ë‚®ì€ ì‹ ë¢°ë„ {confidence:.3f} â†’ ì˜ˆì¸¡ ë³´ë¥˜")

        current_landmark = window[-1]

        left_hand = current_landmark[33*3 : 54*3]
        right_hand = current_landmark[54*3 : 75*3]

        left_mean = np.mean(np.abs(left_hand))
        right_mean = np.mean(np.abs(right_hand))

        if left_mean < HAND_ABSENCE_THRESHOLD and right_mean < HAND_ABSENCE_THRESHOLD:
            hand_absent_counter += 1
            logger.debug(f"[ì† ì‚¬ë¼ì§] frame {i} â†’ {hand_absent_counter}/{HAND_ABSENCE_FRAME_COUNT}")
        else:
            hand_absent_counter = 0

        if hand_absent_counter >= HAND_ABSENCE_FRAME_COUNT:
            counter = Counter(prediction_history)
            if counter:
                best_label, count = counter.most_common(1)[0]
                logger.info(f"[ë¬¸ì¥ ì¢…ë£Œ í›„ë³´] '{best_label}' ë“±ì¥ {count}íšŒ")
                if count >= MIN_CONFIRM_COUNT:
                    logger.info(f"âœ… ë‹¨ì–´ í™•ì • (ì† ì‚¬ë¼ì§ ê¸°ì¤€): '{best_label}'")
                    word_output = best_label
            prediction_history.clear()
            hand_absent_counter = 0

        last_landmark = current_landmark

    if word_output == "":
        logger.info("ğŸ“­ ìµœì¢… ì˜ˆì¸¡ ì—†ìŒ (ì¡°ê±´ ë¶ˆì¶©ì¡±)")
    return word_output