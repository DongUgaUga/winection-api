import numpy as np
from collections import deque, Counter
from tensorflow.keras.models import load_model
from core.log.logging import logger

model = load_model("src/resources/sign_model.h5")
class_names = np.load("src/resources/class_names.npy", allow_pickle=True)

WINDOW_SIZE = 30
CONFIDENCE_THRESHOLD = 0.7
PREDICTION_HISTORY_SIZE = 10
MIN_CONFIRM_COUNT = 7
MOVEMENT_THRESHOLD = 1e-4  # ë³€í™”ëŸ‰ ê¸°ì¤€

prediction_history = deque(maxlen=PREDICTION_HISTORY_SIZE)
last_landmark = None

def calculate_variance(frame, prev_frame):
    diff = frame - prev_frame
    return np.mean(np.square(diff))

def ksl_to_korean(sequence: dict) -> str:
    global last_landmark
    pose = sequence.get('pose', [])
    if len(pose) < WINDOW_SIZE:
        logger.warning(f"[ì…ë ¥ ë¶€ì¡±] í”„ë ˆì„ ìˆ˜ ë¶€ì¡±: {len(pose)}í”„ë ˆì„")
        return ""

    logger.info(f"[ì…ë ¥ ìˆ˜ì‹ ] ì´ í”„ë ˆì„ ìˆ˜: {len(pose)}")

    frames = []
    for idx, frame in enumerate(pose):
        if len(frame) != 75:
            logger.warning(f"[í”„ë ˆì„ ì˜¤ë¥˜] {idx}ë²ˆì§¸ í”„ë ˆì„ì´ 75ê°œ landmark ì•„ë‹˜: {len(frame)}ê°œ")
            return ""
        coords = np.array([[lm['x'], lm['y'], lm['z']] for lm in frame], dtype=np.float32).flatten()
        frames.append(coords)

    frames = np.array(frames, dtype=np.float32)

    word_output = ""

    for i in range(len(frames) - WINDOW_SIZE + 1):
        window = frames[i:i+WINDOW_SIZE]
        pred = model.predict(np.expand_dims(window, axis=0), verbose=0)[0]
        max_idx = int(np.argmax(pred))
        confidence = float(pred[max_idx])
        label = str(class_names[max_idx])

        logger.info(f"[ì˜ˆì¸¡] ìœˆë„ìš° {i} â†’ '{label}' (ì‹ ë¢°ë„: {confidence:.3f})")

        if confidence >= CONFIDENCE_THRESHOLD:
            prediction_history.append(label)
            logger.debug(f"[ëˆ„ì ] '{label}' ì˜ˆì¸¡ ì¶”ê°€ â†’ íˆìŠ¤í† ë¦¬: {list(prediction_history)}")
        else:
            logger.debug(f"[ë¬´ì‹œ] ë‚®ì€ ì‹ ë¢°ë„ {confidence:.3f} â†’ ì˜ˆì¸¡ ë³´ë¥˜")

        current_landmark = window[-1]
        if last_landmark is not None:
            variance = calculate_variance(current_landmark, last_landmark)
            logger.debug(f"[ë³€í™”ëŸ‰] {variance:.8f}")

            if variance < MOVEMENT_THRESHOLD:
                counter = Counter(prediction_history)
                if counter:
                    best_label, count = counter.most_common(1)[0]
                    logger.info(f"[ë‹¤ìˆ˜ê²° í›„ë³´] '{best_label}' ë“±ì¥ {count}íšŒ")
                    if count >= MIN_CONFIRM_COUNT:
                        logger.info(f"âœ… ë‹¨ì–´ í™•ì •: '{best_label}'")
                        word_output = best_label
                    else:
                        logger.info("âŒ í™•ì • ì‹¤íŒ¨: ë“±ì¥ íšŸìˆ˜ ë¶€ì¡±")
                prediction_history.clear()

        last_landmark = current_landmark

    if word_output == "":
        logger.info("ğŸ“­ ìµœì¢… ì˜ˆì¸¡ ì—†ìŒ (ì¡°ê±´ ë¶ˆì¶©ì¡±)")
    return word_output
